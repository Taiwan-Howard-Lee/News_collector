# Singapore News Intelligence Dashboard

An AI-powered news aggregation and personalization system that curates Singapore news content and presents it through an intelligent, user-friendly interface.

## ğŸ¯ Project Overview

This system combines modern web scraping, AI processing, and personalized user experiences to deliver relevant Singapore news content. It features:

- **Intelligent News Curation**: Automated scraping and processing of Singapore news sources
- **AI-Powered Personalization**: Content relevance scoring based on user profiles
- **Modern Web Interface**: Responsive dashboard with search, filtering, and theming
- **User Engagement**: Personalized onboarding and engagement tracking

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Flutter App    â”‚    â”‚   Python Backend â”‚    â”‚   PostgreSQL/   â”‚
â”‚   (Mobile/Web)   â”‚â”€â”€â”€â–¶â”‚   (FastAPI +     â”‚â”€â”€â”€â–¶â”‚   SQLite DB     â”‚
â”‚                  â”‚    â”‚   Async Scraping)â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚                        â”‚
         â–¼                        â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Local Storage  â”‚    â”‚   Gemini AI     â”‚    â”‚   News Sources  â”‚
â”‚   (Hive/SQLite)  â”‚    â”‚   (Processing)  â”‚    â”‚   (Web Scraping)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
News_collector/
â”œâ”€â”€ ğŸ“ backend/                 # Python backend services
â”‚   â”œâ”€â”€ ğŸ“ api/                # FastAPI endpoints
â”‚   â”œâ”€â”€ ğŸ“ database/           # Database connections
â”‚   â”œâ”€â”€ ğŸ“ models/             # Data models
â”‚   â”œâ”€â”€ ğŸ“ scrapers/           # Web scraping pipeline
â”‚   â”œâ”€â”€ ğŸ“ utils/              # Utility functions
â”‚   â”œâ”€â”€ main.py               # FastAPI application
â”‚   â””â”€â”€ run_scraper.py        # Scraper execution
â”œâ”€â”€ ğŸ“ frontend/               # Flutter mobile/web app
â”‚   â”œâ”€â”€ ğŸ“ lib/               # Dart source code
â”‚   â”‚   â”œâ”€â”€ ğŸ“ models/        # Data models
â”‚   â”‚   â”œâ”€â”€ ğŸ“ providers/     # State management
â”‚   â”‚   â”œâ”€â”€ ğŸ“ screens/       # UI screens
â”‚   â”‚   â”œâ”€â”€ ğŸ“ services/      # API & storage services
â”‚   â”‚   â”œâ”€â”€ ğŸ“ widgets/       # Reusable UI components
â”‚   â”‚   â””â”€â”€ main.dart         # App entry point
â”‚   â”œâ”€â”€ ğŸ“ assets/            # Images, icons, animations
â”‚   â””â”€â”€ pubspec.yaml          # Flutter dependencies
â”œâ”€â”€ ğŸ“ config/                 # Configuration files
â”œâ”€â”€ ğŸ“ data/                   # Data storage
â”œâ”€â”€ ğŸ“ test/                   # Test files
â”œâ”€â”€ PROJECT_PLAN.md           # Detailed project plan
â”œâ”€â”€ CODE_COMPILATION.md       # Complete code reference
â””â”€â”€ requirements.txt          # Python dependencies
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- Google Account (for Apps Script and Sheets)
- Google Cloud Project (for API access)

### Backend Setup
```bash
# 1. Clone and navigate to project
cd News_collector

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 3. Install dependencies
pip install -r requirements.txt

# 4. Set up environment variables
cp config/env.example config/.env
# Edit config/.env with your API keys and database URL

# 5. Run the FastAPI server
uvicorn backend.main:app --reload

# 6. Run the scraper
python backend/run_scraper.py --workers 10
```

### Frontend Setup (Flutter)
```bash
# 1. Navigate to frontend directory
cd frontend

# 2. Get Flutter dependencies
flutter pub get

# 3. Run on desired platform
flutter run                    # For connected device
flutter run -d chrome         # For web
flutter run -d macos          # For macOS desktop

# 4. Build for production
flutter build apk             # Android APK
flutter build web             # Web build
flutter build macos           # macOS app
```

## âœ¨ Features

### âœ… Implemented
- **Modern UI/UX**: Responsive design with dark/light themes
- **User Personalization**: Profile-based content curation
- **Advanced Search**: Real-time filtering and sorting
- **Async Scraping**: High-performance concurrent processing
- **Database Integration**: PostgreSQL/SQLite support
- **Error Handling**: Comprehensive error states and logging

### ğŸš§ In Development
- AI-powered relevance scoring
- Interactive chat interface
- Real-time notifications
- Advanced analytics

## ï¿½ï¸ Technology Stack

### Backend
- **FastAPI**: Modern Python web framework
- **SQLAlchemy**: Database ORM
- **PostgreSQL/SQLite**: Database storage
- **AsyncIO**: Concurrent processing
- **BeautifulSoup**: Web scraping

### Frontend
- **Flutter**: Cross-platform mobile/web framework
- **Dart**: Programming language
- **Riverpod**: State management
- **Hive**: Local storage and caching

### AI & Processing
- **Google Gemini API**: Content summarization
- **Custom algorithms**: Relevance scoring
- **Natural language processing**: Content analysis

## ï¿½ Data Flow

1. **Discovery**: Automated discovery of news articles from Singapore sources
2. **Extraction**: Content extraction and cleaning
3. **Processing**: AI-powered summarization and relevance scoring
4. **Storage**: Structured data storage in Google Sheets
5. **Presentation**: Personalized dashboard display
6. **Interaction**: User engagement and feedback collection

## ğŸ”§ Configuration

### Environment Variables
```bash
# Database
DATABASE_URL=postgresql://user:pass@host:port/db

# Google APIs
GOOGLE_SHEETS_CREDENTIALS_PATH=config/credentials.json
GOOGLE_SHEET_ID=your_sheet_id_here

# AI Processing
GEMINI_API_KEY=your_gemini_api_key
```

### Google Sheets Structure
The system automatically creates these sheets:
- **Dashboard**: Curated articles for display
- **Articles**: Raw scraped content
- **User_Profiles**: User personalization data
- **Saved_Insights**: User interactions and feedback
- **Logs**: System activity logs

## ğŸ§ª Testing

```bash
# Run backend tests
python -m pytest test/

# Test scraping pipeline
python backend/run_scraper.py --workers 5

# Test API endpoints
curl http://localhost:8000/api/health
```

## ğŸ“ˆ Performance

- **Concurrent Scraping**: Up to 25 parallel workers
- **Response Time**: <2s average for dashboard load
- **Scalability**: Handles 1000+ articles efficiently
- **Uptime**: 99.9% availability target

## ğŸ” Security & Privacy

- **Authentication**: Google OAuth integration
- **Data Privacy**: User data stored in private Google Sheets
- **API Security**: Rate limiting and input validation
- **HTTPS**: Secure communication protocols

## ï¿½ Documentation

- **[PROJECT_PLAN.md](PROJECT_PLAN.md)**: Detailed project roadmap
- **[CODE_COMPILATION.md](CODE_COMPILATION.md)**: Complete code reference
- **[frontend/README.md](frontend/README.md)**: Flutter app documentation

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ï¿½ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

For issues and questions:
1. Check the documentation
2. Search existing issues
3. Create a new issue with detailed information

---

**Built with â¤ï¸ for the Singapore tech community**
